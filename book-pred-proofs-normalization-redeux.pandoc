<style>
table {
  border-collapse: collapse;
  width: 100%;
}

th, td {
  text-align: left;
  padding: 8px;
}

tr:nth-child(even) {background-color: #f2f2f2;}
</style>

<br>
<br>

# Natural deduction, definitions, and normalization

<br>

- [The rules as definitions](#the-rules-as-definitions)
- [Prior and tonk](#prior-and-tonk)
- [Conservation and the subformula property](#conservation-and-the-subformula-property)
- [The subformula property and normalization](#the-subformula-property-and-normalization)

<br>

## The rules as definitions

In this course we started with models, from which we can define validity, and then we turned to proof systems. From this vantage point, it looks like what is happening in a proof system is that we are taking certain valid arguments as primitive rules, and then we are deriving other validities from these. This then raises the question of how and by what means one chooses the rules. Why choose one set of validities as opposed to another set of validities as *the* rules? Is the idea that some are more easily justified or epistemically basic than others, and if so by what means?

One answer to these questions comes from Gentzen, who first developed natural deduction proof systems:[^1]

&nbsp; &nbsp; &nbsp;  <img src="https://logic-teaching.github.io/pred/texts/Gentzen%201969%20-%20Investigations%20into%20Logical%20Deduction%20p.%2080.png
" alt="Gentzen on definitions" width="700"/>

[^1]: p. 80 of: [Gentzen, Gerhard. 1969. “Investigations into Logical Deduction.” In The Collected Papers of Gerhard Gentzen, edited by M. E. Sazbo, 68–131. Studies in Logic and the Foundations of Mathematics. Amsterdam: North-Holland.](https://logic-teaching.github.io/pred/texts/Gentzen%201969%20-%20Investigations%20into%20Logical%20Deduction.pdf)

To get the sense of Gentzen's answer, we can ask the specific question: what justifies the elimination rule for arrow? Recall the elimination rule for arrow is:

<video controls width="300" src="https://logic-teaching.github.io/pred/vid/ND-Earrow-vid.mp4"/> </video>
<br>

The first premise $\phi\rightarrow \psi$ of arrow elimination means, "in the sense afforded by the introduction" rule for arrow, that there is a proof from $\phi$ to $\psi$. If one write this proof out, the $\phi$ at the top of the bracket is justified as a hypothetical assumption. But the second premise $\phi$ of arrow elimination, when deployed in a proof, comes with some reason to believe $\phi$, say rule XYZ. Then simply put this justification in place of the hypothetical assumption, and one has a proof from $\phi$ to $\psi$, and since one has a reason for $\phi$, one then has a reason for $\psi$. In a picture:

<video controls width="700" src="https://logic-teaching.github.io/pred/vid/conv-arrow.mp4"/> </video>

<br>

More concretely, one can get the sense in which Gentzen thinks that the elimination rule for arrow is a consequence of the introduction rule for arrow by looking at the following three proofs. In the first, try to do a very simple arrow elimination proof:

```{.ProofChecker .GamutNDPlus submission="none"}
 (Fa/\Fb)/\Fc, ((Fa/\Fb)/\Fc)->Fb :|-: Fb
|(Fa/\Fb)/\Fc :assumption
|((Fa/\Fb)/\Fc)->Fb :assumption
```

In the second, we take the meaning of the arrow statement in the premise to be: there is a proof taking us from $((Fa\wedge Fb)\wedge Fc)$ to $Fb$. Expand the previous proof so that the end of the proof is the same, but it has above it a line which reads `((Fa/\Fb)/\Fc)->Fb` and which is justified by an arrow introduction:

```{.ProofChecker .GamutNDPlus submission="none"}
 (Fa/\Fb)/\Fc :|-: Fb
|(Fa/\Fb)/\Fc :assumption
```

In the third, try to do a proof which removes both the introduction and elimination of arrow at the end and which just works by conjunction elimination:

```{.ProofChecker .GamutNDPlus submission="none"}
 (Fa/\Fb)/\Fc :|-: Fb
|(Fa/\Fb)/\Fc :assumption
```

This example illustrates how the introduction rule for arrow can be taken as a definition of arrow: the arrow in $\phi\rightarrow \psi$ is defined as there being a proof going from antecedent $\phi$ to consequent $\psi$. The elimination rule is then said to follow from this definition since it tells one how to move from premises $\phi\rightarrow \psi$ and $\phi$ to conclusion $\psi$ by putting the proof associated to $\phi\rightarrow \psi$ together with the proof of $\phi$ to get a proof of $\psi$.

But one obvious limitation of this is is that it only works when the assertion of $\phi\rightarrow \psi$ can be thought of as a proof going from $\phi$ to $\psi$. In the above illustration, it could be so conceived, but sometimes when we assert a conditional we do not have such a proof in mind. For instance, if I say "if Adriana is nice then Brianna is nice," then I do not seem to have any such proof in mind. And likewise there is no way to carry out the procedure described up above for the simple associated proof:

```{.ProofChecker .GamutNDPlus submission="none"}
 Na, Na->Nb :|-: Nb
|Na :assumption
|Na->Nb :assumption
```

We can complete this proof by doing arrow elimination, but there is no way to expand this proof so that we have `Na->Nb` not as an assumption but as the conclusion of an instance of arrow introduction.

There are various ways around this. For instance, one can consider idealized proof systems in which there is a rule like "from Adriana being nice, infer Briana being nice," and perhaps one can consider typical assertions of conditionals as happening in such a system.[^2]

[^2]: These are the *atomic system(s)* in the literature on proof-theoretic semantics, e.g. [Schroeder-Heister, Peter. 2018. “Proof-Theoretic Semantics.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Spring 2018. Metaphysics Research Lab, Stanford University.](https://plato.stanford.edu/archives/spr2018/entries/proof-theoretic-semantics/).

<br>

## Prior's example of tonk

One might think of definitions as being true by virtue of meaning, in the unproblematic sense of a stipulation about how to use words. In this sense, Gentzen's proposal might seem like a version of the view that the introduction and elimination rules are true by virtue of meaning. It was with this kind of view that Prior was interested:

&nbsp; &nbsp; &nbsp;  <img src="https://logic-teaching.github.io/pred/texts/Prior%201960%20-%20The%20runabout%20inference-ticket-again.png
" alt="Prior on " width="700"/>

Prior's famous counterexample to this was an imaginary connective he called *tonk*, which has an introduction rule like disjunction and an elimination rule like conjunction.[^3] The problem with saying that the validity of these inferences is given simply by the meaning of "tonk" is, in Prior's view, that from these rules one can derive anything. For instance, here is the a derivation that $Fa\vdash Ga$:

1. Fa :assumption
2. Fa tonk Ga :I tonk 1.
3. Ga :E tonk 2

(The step from 1 to 2 holds because "tonk" has an introduction rule like disjunction, and the step from 2 to 3 holds because "tonk" has an elimination rule like conjunction). There are obviously some properties $F,G$ and objects $a$ such that we want to say that we can infer from $Fa$ to $Ga$, but we certainly do not want to be committed to this in general.

[^3]: [Prior, Arthur N. 1960. “The Runabout Inference-Ticket.” Analysis 21 (2): 38–39.](https://logic-teaching.github.io/pred/texts/Prior%201960%20-%20The%20runabout%20inference-ticket.pdf).

An obvious reaction to Prior's counterexample is that the introduction and elimination rules for "tonk" are mismatched in a way in which the introduction and elimination rules for the propositional connectives and quantifiers are not. But it is difficult to say more about what this "mismatch" amounts to. Another reaction is to note that Gentzen's proposal was more specific than "any collection of introduction and elimination rules determines a meaning." However, one way to think about Prior is as issuing a challenge to Gentzen: if it is okay to "lay down" the introduction rule as a definition, why is it not similarly okay to "lay down" pairs of introduction rules and elimination rules as definitions?

<br>

## Conservation and the subformula property

Belnap suggested that what distinguishes tonk from the usual propositional connectives is conservativity.[^4] Suppose that we have a system of rules which allows us to define a validity relation $\vdash_1$. And suppose we add a new set of rules governing some new connectives to get a validity relation $\vdash_2$. Since we are thinking that the old rules apply to the new connective, we trivially have:

[^4]: [Belnap, Nuel D. 1962. “Tonk, Plonk and Plink.” Analysis 22 (6): 130–34.](https://logic-teaching.github.io/pred/texts/Belnap%201962%20-%20Tonk,%20plonk%20and%20plink.pdf)

- If $\phi_1, \ldots, \phi_n\vdash_1 \phi$ then $\phi_1, \ldots, \phi_n \vdash_2 \phi$, for all formulas $\phi_1, \ldots, \phi_n, \phi$, regardless of whether they contain the old or new connectives.

We say that the new validity relation is *conservative* over the old validity relation if the converse happens, for formulas which do not involve the new connectives:

 - If $\phi_1, \ldots, \phi_n\vdash_2 \phi$ then $\phi_1, \ldots, \phi_n \vdash_1 \phi$, for all formulas $\phi_1, \ldots, \phi_n, \phi$, for all formulas $\phi_1, \ldots, \phi_n, \phi$ formed from the old connectives.

This is just a way of saying that the new connectives and rules do not allow us to prove anything about the old connectives which we could not already prove from the rules governing the old connectives themselves.

Obviously Prior's tonk example violates the conservation constraint, since we can prove anything using the tonk rules, and hence things like:

1. Fa->Fb :assumption
2. (Fa->Fb) tonk (Ga->Gb) :I tonk 1.
3. Ga->Gb :E tonk 2

Hence, if we added tonk to our logic to get a validity relation $\vdash_2$, then we would have $Fa\rightarrow Fb \vdash_2 \; Ga\rightarrow Gb$, even though we clearly cannot prove $Fa\rightarrow Fb \vdash Ga\rightarrow Gb$ using the rules for arrow and the other connectives we have learned.

This then raises the question of whether the rules we have learned for the connectives are conservative. One way to state the question would be as to whether our validity relation $\vdash$ is conservative over the smaller set of rules formed by deleting the introduction and elimination rules for any given connective. Concretely: is our validity relation $\vdash$ which includes the introduction and elimination rules for arrow conservative over the smaller system $\vdash_0$ which does not include the introduction and elimination rules for arrow? This is to ask: is any fact about conjunction  provable using the facts about arrow already provable from the rules governing conjunction itself?

It turns out that the answer to this question is "yes" and relates to a property of the rules we have been learning called the *subformula* property. One formula is a subformula of a second just if the first formula is part of what one cites when one describes why the second formula is a formula. For instance:

- $Fa$ is a subformula of $Fa\rightarrow Fb$
- $Fa\rightarrow Fb$ is a subformula of $(Fa\rightarrow Fb)\wedge Fc$
- $Fa\rightarrow Fb$ is *not* a subformula of $Fa\wedge (Fb\rightarrow Fc)$

It turns out that the rules for the connectives and quantifiers which we have been learning so far have the following feature:[^9]

[^9]: In our system, we used arrow in stating the elimination rules for disjunction and existential. But this is obviously avoidable, and we could have rather used brackets in this case without arrow introductions under them. That is, we could have avoided using arrow in stating the elimination rules for disjunction and existential if we had allowed ourselves a more liberal use of brackets. The Subformula Theorem will thus not technically hold for our system when the formulas contain disjunction and existentials. But it will hold for a notational variant of our system in which the rules for disjunction and existential are not stated in terms of arrow.

- (Subformula Theorem): If $\phi_1, \ldots, \phi_n\vdash \phi$, then there is a proof of this in which each formula appearing on a line of the proof is a subformula of either the premises $\phi_1, \ldots, \phi_n$ or the conclusion $\psi$.

We will speak, in a moment, about the reason why this holds. But let us just note that this suffices to get conservativity. For, suppose that we proved some fact about conjunction using the rules for arrow, and suppose that the proof was e.g. $\phi_1, \ldots, \phi_n \vdash \phi$, where $\phi_1, \ldots, \phi_n, \phi$ did not involve arrow but only conjunction and disjunction. Then there is a proof of it where all the formulas in the proof are subformulas of $\phi_1, \ldots, \phi_n, \phi$ and hence involve only conjunction. Since the rules are tied to the main connectives, this means that there are no arrow rules deployed in this proof. Hence, we have a proof of this which uses only facts about conjunction.

<br>

## The subformula property and normalization

The reason why the subformula property holds is a feature of our proof-system called normalization. The formula definition of normalization is a little beyond what we are able to formally state here, but it is easy to give an intuitive idea since in some sense we have been working with it all along.[^8] Namely, the way to produce normal proofs is to apply elimination rules at the top of the proof and introduction rules down at the bottom of the proof. Here is a simple example where it is easy to produce a normal proof using conjunction elimination at the top and disjunction introduction at the bottom:

[^8]: For more details, see any textbook treatment of an introduction to proof-theory, like: Negri, Sara and von Plato, Jan. 2008. Structural Proof Theory. Cambridge University Press.

```{.ProofChecker .GamutNDPlus submission="none"}
 (Fa/\Fb)/\Fc :|-: Fb\/Fd
|(Fa/\Fb)/\Fc :assumption
```

It is easy to see that this proof has the subformula property, by inspection. Moreover, it is at least plausible to think that any proof which worked via elimination rules at the top and introduction rules at the bottom would have the subformula property. For, lines near the top would be subformulas of premises since that is how elimination rules work; and lines near the bottom would be subformulas of conclusions since that it is how the introduction rules work.

But how could a proof fail to have the subformula property? Well, we just introduce the phenomena that Gentzen himself drew attention to: an introduction rule for a connective followed immediately by an elimination rule for that same connective. For instance, even though our previous example only pertained to conjunction and disjunction, we could easily introduce extraneous lines involving arrow, by adding a line that says, for instance, `((Fa/\Fb)/\Fc)->Fb` and which is justified by arrow introduction follow by an arrow elimination:

```{.ProofChecker .GamutNDPlus submission="none"}
 (Fa/\Fb)/\Fc :|-: Fb\/Fd
|(Fa/\Fb)/\Fc :assumption
```

Proofs like this-- *non-normal proofs*-- seem kind of frivolous, as if they would not actually occur in the practice of giving arguments. But they are actually the proofs that occur most frequently in the practice of giving arguments. This is because we like to separate out arguments into discrete parts which we then combine, and the act of combination produces non-normal proofs. To take a simple example, first complete the proof of "someone is respected by everyone implies everyone respects someone":

```{.ProofChecker .GamutNDPlus submission="none"}
 :|-: EyAxRxy->AxEyRxy
| EyAxRxy :assumption
```

This proof is rather tricky, and we would prefer not to have to redo it over and over again. Suppose that we are given the problem

$\exists \; y \; \forall \; x \; (Rxy\wedge Sxy)\vdash \forall \; x \; \exists \; y \; Rxy \wedge \forall x \; \exists \; y \; Sxy$.

For instance, this corresponds to an inference like: "if someone is both $r$espected by and is held in high e$s$teem by everyone, then everyone respects someone and everyone holds someone in high esteem." The natural way to prove this one would be to follow these steps:

1. Write out the proof that $\exists \; y \; \forall \; x \; (Rxy\wedge Sxy)$ implies $\exists \; y \; \forall \; x \; Rxy$ and $\exists \; y \; \forall \; x \; Sxy$.
2. Repeat the previous proof with respect to $R$.
3. Repeat the previous proof with respect to $S$.
4. Combine the two conclusions with a conjunction.

Try to follow this strategy to complete the following proof:

```{.ProofChecker .GamutNDPlus submission="none"}
 EyAx(Rxy/\Sxy) :|-: AxEyRxy/\AxEySxy
|EyAx(Rxy/\Sxy) :assumption
```

Your version of the proof should have two separate instances of the introduction rule for arrow followed by the elimination rule for arrow. Now try to do a "normal" proof which does not have this feature:

```{.ProofChecker .GamutNDPlus submission="none"}
 EyAx(Rxy/\Sxy) :|-: AxEyRxy/\AxEySxy
|EyAx(Rxy/\Sxy) :assumption
```

These are lecture notes written by Sean Walsh. They are run on [carnap.io](http://www.carnap.io).[^5]

[^5]: which is:

